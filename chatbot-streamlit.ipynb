{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T18:36:22.153188Z",
     "iopub.status.busy": "2024-09-09T18:36:22.152757Z",
     "iopub.status.idle": "2024-09-09T18:36:22.170937Z",
     "shell.execute_reply": "2024-09-09T18:36:22.169693Z",
     "shell.execute_reply.started": "2024-09-09T18:36:22.153142Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import torch\n",
    "import streamlit as st\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Set up the Streamlit app\n",
    "st.set_page_config(page_title=\"Therapy Chatbot\", layout=\"wide\")\n",
    "\n",
    "# Custom CSS to style the chat interface\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    ".stTextInput > div > div > input {\n",
    "    border-radius: 20px;\n",
    "}\n",
    ".stButton > button {\n",
    "    border-radius: 20px;\n",
    "    float: right;\n",
    "}\n",
    ".chat-message {\n",
    "    padding: 1.5rem; border-radius: 0.5rem; margin-bottom: 1rem; display: flex\n",
    "}\n",
    ".chat-message.user {\n",
    "    background-color: #2b313e\n",
    "}\n",
    ".chat-message.bot {\n",
    "    background-color: #475063\n",
    "}\n",
    ".chat-message .avatar {\n",
    "  width: 20%;\n",
    "}\n",
    ".chat-message .avatar img {\n",
    "  max-width: 78px;\n",
    "  max-height: 78px;\n",
    "  border-radius: 50%;\n",
    "  object-fit: cover;\n",
    "}\n",
    ".chat-message .message {\n",
    "  width: 80%;\n",
    "  padding: 0 1.5rem;\n",
    "  color: #fff;\n",
    "}\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Load the model (unchanged)\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"Vedika8/Therapy_chatbot\", torch_dtype=torch.float16)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Vedika8/Therapy_chatbot\")\n",
    "    return model, tokenizer, device\n",
    "\n",
    "model, tokenizer, device = load_model()\n",
    "\n",
    "# Functions for prompt formatting and output cleaning (unchanged)\n",
    "def format_prompt(prompt, chat_history):\n",
    "    history = \"\".join([f\"User: {entry['user']}\\nAI: {entry['ai']}\\n\" for entry in chat_history])\n",
    "    return f\"[INST] <<SYS>> You are a virtual AI therapy assistant. Your role is to provide thoughtful and supportive responses. Always ensure that you complete your last sentence with a period.<</SYS>> {history}User: {prompt.strip()} [/INST]\"\n",
    "\n",
    "def clean_output(output_text, input_text):\n",
    "    # Ensure special tokens are removed, but not meaningful text\n",
    "    output_text = output_text.replace(input_text, \"\")\n",
    "    output_text = output_text.replace(\"[INST]\", \"\").replace(\"[/INST]\", \"\").replace(\"(period)\",\"\").replace(\"(Period)\",\"\")\n",
    "    output_text = output_text.replace(\"1)\", \"\\n\\n1)\").replace(\"2)\", \"\\n\\n2)\").replace(\"3)\", \"\\n\\n3)\")\\\n",
    "        .replace(\"4)\", \"\\n\\n4)\").replace(\"5)\", \"\\n\\n5)\").replace(\"6)\", \"\\n\\n6)\").replace(\"7)\", \"\\n\\n7)\").replace(\"8)\", \"\\n\\n8)\").replace(\"9)\", \"\\n\\n9)\")\n",
    "    return output_text.strip()\n",
    "\n",
    "# Initialize chat history\n",
    "if \"chat_history\" not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "    \n",
    "# New Chat Button: Clears the chat history to start a new session\n",
    "if st.button(\"New Chat\"):\n",
    "    st.session_state.chat_history = []\n",
    "\n",
    "# Chat interface\n",
    "st.markdown(\"<h1 style='text-align: center;'>Therapy Chatbot 🤗</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "# Display chat messages\n",
    "for message in st.session_state.chat_history:\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(message[\"user\"])\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.write(message[\"ai\"])\n",
    "\n",
    "# User input\n",
    "user_input = st.chat_input(\"Type your message here...\")\n",
    "\n",
    "if user_input:\n",
    "    # Add user message to chat history\n",
    "    st.session_state.chat_history.append({\"user\": user_input, \"ai\": \"\"})\n",
    "    \n",
    "    # Display user message\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(user_input)\n",
    "\n",
    "    # Generate bot response\n",
    "    formatted_prompt = format_prompt(user_input, st.session_state.chat_history[:-1])\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            temperature=0.6,\n",
    "            max_new_tokens=500,\n",
    "            top_k=50,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.2,\n",
    "            no_repeat_ngram_size=3,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    clean_response = clean_output(response, formatted_prompt)\n",
    "    \n",
    "    # Update the last message in chat history with bot response\n",
    "    st.session_state.chat_history[-1][\"ai\"] = clean_response\n",
    "    \n",
    "    # Display bot response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.write(clean_response)\n",
    "\n",
    "# Clean up memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T18:36:29.965471Z",
     "iopub.status.busy": "2024-09-09T18:36:29.964781Z",
     "iopub.status.idle": "2024-09-09T18:36:50.238304Z",
     "shell.execute_reply": "2024-09-09T18:36:50.237143Z",
     "shell.execute_reply.started": "2024-09-09T18:36:29.965399Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.4.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.4)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (9.5.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (16.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.43)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.4.1)\n",
      "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\n",
      "Requirement already satisfied: narwhals>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.4.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25,>=20->streamlit) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
      "Successfully installed pydeck-0.9.1 pyngrok-7.2.0 streamlit-1.38.0 watchdog-4.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T18:37:28.912092Z",
     "iopub.status.busy": "2024-09-09T18:37:28.911418Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: https://f2d0-34-69-35-187.ngrok-free.app\n",
      "Running Streamlit app...\n",
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\n",
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://172.19.2.2:8501\n",
      "  External URL: http://34.69.35.187:8501\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 3/3 [01:08<00:00, 22.69s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  6.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from pyngrok import ngrok\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Set your ngrok auth token\n",
    "ngrok.set_auth_token(\"2lnntTQURjEGdZOmNXeg2WyjMoR_5zmkPGZhkXexEtUsKBaDJ\")  # Replace with your actual token\n",
    "\n",
    "# Get the dev server port (defaults to 8501)\n",
    "port = 8501\n",
    "\n",
    "# Open a ngrok tunnel to the dev server\n",
    "public_url = ngrok.connect(port).public_url\n",
    "print(f\"Public URL: {public_url}\")\n",
    "\n",
    "# Update the environment variable for Streamlit to use\n",
    "os.environ['STREAMLIT_SERVER_PORT'] = str(port)\n",
    "\n",
    "# Run the Streamlit app\n",
    "print(\"Running Streamlit app...\")\n",
    "subprocess.Popen(['streamlit', 'run', 'app.py'])\n",
    "\n",
    "# Keep the notebook running\n",
    "import time\n",
    "while True:\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
